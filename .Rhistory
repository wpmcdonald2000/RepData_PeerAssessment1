fitControl <- trainControl(preProcOptions = list(thresh=0.8))
modelFit2 <- train(diagnosis ~ ., method="glm", trControl = fitControl, preProcess = "pca", data = training2)
modelFit
modelFit2
modelFit <- train(diagnosis~.,data = training2, method="glm", trControl = fitControl)
modelFit
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
data(segmentationOriginal)
names(segmentationOriginal)
inTrain <- createDataPartition(y= segmentationOriginal$Case, p=0.7, list = FALSE)
set.seed(125)
training <- segmentationOriginal[inTrain,]
modFit <- train(Case ~ .,method = rpart, data = training )
modFit <- train(Case ~ .,method = "rpart", data = training )
print(modFit$finalModel)
testing <- segmentationOriginal[-inTrain,]
predict(modFit, newdata = testing)
predict(modFit, newdata = testing[TotalIntench2 == 23000],)
testing[TotalIntench2 == 23000,]
testing[TotalIntenCh2 == 23000,]
testing["TotalIntenCh2" == 23000,]
head(training)
modFit <- train(Class ~ .,method = "rpart", data = training )
print(modFit$finalModel)
install.packages("ratt")
install.packages("rattle")
library(rattle)
fancyRPartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classfication Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
olive <- olive[,-1]
names(olive)
modFit <- train(Area ~ ., method = "rpart", data = olive)
print(modFit$finalModel)
newdata <- as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
modFit <- train(Area ~ ., method = "tree", data = olive)
?tree
install.packages("tree")
library(tree)
?tree
modelFit <- tree(Area ~ ., data = olive)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
predict(modelFit, newdata = as.data.frame(t(colMeans(olive))))
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAHeart)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(trainSA)
mdl <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method='glm', data=trainSA, family='binomial')
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
mdl$finalModel
trainSA$chd
missClass(trainSa$chd, testSA$chd)
missClass(trainSA$chd, testSA$chd)
missClass(testSA$chd, trainSA$chd)
testSA$chd
mdl$chd
mdl$predict
mdl2 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method='glm', data=trainSA, family='binomial')
mdl2$finalModel
mdl$finalModel
mdl$chd
mdl$values
?train
predict(mdl, newdata = trainSA)
trainSA$chd
mdl
mdl2
predict(mdl$chd, newdata = trainSA)
mdl$chd
mdl
mdl$finalModle
mdl$finalModel
train$chd
trainSA$chd
mdl$parameter
mdl$results
?predict
predict(mdl, newdata = trainSA$chd)
predict(mdl, newdata = trainSA
)
mdl
names(mdl)
mdl$results
mdl$xlevels
mdl$method
mdl$modleInfo
mdl$modelInfo
names(mdl)
mdl$resampledCM
mdl$pred
mdl$method
mdl$pred
mdl$dots
mdl$trainingData
mdl$trainingData.outcome
mdl$trainingData[.outcome]
mdl$trainingData[outcome]
mdl$outcome
names(mdl)
mdl$xlevels
mdl$resample
mdl$trainingData
mdl$.outcome
mdl$trainingData
mdl$trainingData.outcome
mdl$trainingData[,.outcome]
mdl$trainingData[,outcome]
mdl$trainingData[[.outcome]]
mdl$trainingData[[,.outcome]]
out <- mdl$trainingData
names(out)
out$.outcome
missClass(trainSA$chd, out$.outcome)
trainSA$chd
out2 <- mdl2$.outcome
out2
names(mdl2)
mdl2
names(mdl)
mdl2$trainingData
mdl2$trainingData$.outcome
trainSA$chd
missClass(trainSA$chd, mdl2$trainingData$.outcome)
names(mdl2)
mdl2$resample
mdl2$resampledCM
mdl2$maximize
mdl2$results
mdltest <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method='glm', data=testSA, family='binomial')
mdltest$results
data(vowel.train)
data(vowel.test)
names(vowel.train)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.test)
set.seed(33833)
modelrf <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
modelrf <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
?varimp
?varImp
varImp(modelrf)
read.csv("pml-training.csv", na.strings=c("NA", "#DIV/0!"), strip.white = T)
read.csv("https://github.com/wpmcdonald2000/PracticalMachineLearning/blob/master/pml-training.csv", na.strings=c("NA", "#DIV/0!"), strip.white = T)
read.csv("/Users/williammcdonald/PracticalMachineLearning/pml-training.csv", na.strings=c("NA", "#DIV/0!"), strip.white = T)
train <- read.csv("/Users/williammcdonald/PracticalMachineLearning/pml-training.csv", na.strings=c("NA", "#DIV/0!"), strip.white = T)
dim(train)
inTrain <- createDataPartition(y=train$classe, p=0.7, list=FALSE)
training <- train[inTrain,]
validation <- train[-inTrain,]
names(training)
str(training)
dim(training)
library(corrplot)
install.packages("corrplot")
library("corrplot", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages("dplyr")
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
training <- select(training, -(X:num_window))
dim(training)
training <- training[ ,apply(training, 2, function(x) sum(is.na(x)) == 0)]
nzv <- nearZeroVar(training, saveMetrics=TRUE)
summary(nzv)
dim(training)
summary(training)
str(training)
trainCor <- cor(select(training,-classe))
corrplot(trainCor, method="color", tl.pos="n")
trainHighlyCor <- findCorrelation(trainCor, cutoff = 0.90)
training <- training[,-trainHighlyCor]
dim(training)
set.seed(1379)
modFit <- train(classe ~ ., data=training, method="rf", trControl=trainControl(method="cv", number=10))
modFit$finalModel
plot(modFit, log = "y", lwd = 2, main = "Model Accuracy")
plot(varImp(modFit))
set.seed(12345)
model <- randomForest(classe ~ ., data = training)
model
imp <- varImp(model)
imp$Variable <- row.names(imp)
imp[order(imp$Overall, decreasing = TRUE),]
pred <- predict(modFit, newdata = validation)
cm <- confusionMatirx(pred, validation$classe)
cm <- confusionMatrix(pred, validation$classe)
cm
validation$Predictions <- pred == validation$classe
qplot(data=validation[,-ncol(validation)], x=yaw_belt, y=pitch_forearm, colour=classe, main="Validation Dataset")
pml_testing <- read.csv("pml-testing.csv", na.strings=c("NA", "#DIV/0!"))
pml_testing <- read.csv("/Users/williammcdonald/PracticalMachineLearning/pml-testing.csv", na.strings=c("NA", "#DIV/0!"))
test_pred <- predict(modFit, newdata=pml_testing)
test-pred
test_pred
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(test_pred)
pml_write_files(test_pred)
pml_testing$classe
names(pml_testing)
predict(model, testing)
model
dim(testing)
names(testing)
?select
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""), strip.white = T)
test <- read.csv("/Users/williammcdonald/PracticalMachineLearning/pml-testing.csv", na.strings=c("NA",""), strip.white=T)
test
str(test)
names(test)
test[,160]
pml_testing <- read.csv("/Users/williammcdonald/PracticalMachineLearning/pml-training.csv", na.strings=c("NA",""), strip.white=T)
str(train)
train <- train[ ,apply(train, 2, function(x) sum(is.na(x)) == 0)]
dim(train)
train <- train[, 8:60]
CorrelationCheck <- cor(select(train,-classe))
corrplot(CorrelationCheck, method="color", tl.pos="n")
HighlyCorrelated <- findCorrelation(CorrelationCheck, cutoff = 0.90)
train <- train[,-HighlyCorrelated]
set.seed(1379)
modFit <- train(classe ~ ., data=training, method="rf", trControl=trainControl(method="cv", number=10))
modFit <- train(classe ~ ., data=training, method="rf")
?randomForest
modFit <- train(classe ~ ., data=train, method="rf", trControl=trainControl(method="cv", number=10))
model <- randomForest(classe ~ . , data = train)
model
model$finalModel
model[4]
model[oob]
model[1]
model[2]
model[6]
model[7]
model[8]
model[9]
model[10]
model
model[err.rate]
model
plot(model)
imp <- varImp(model)
imp$Variable
row.names(imp)
imp$overall
imp
imp[order(imp$Overall, decreasing = T),]
imp$Variable <- row.names(imp)
imp[order(imp$Overall, decreasing = T),]
plot(varImp(model))
plot(model)
modFit <- train(classe ~ ., data=training, method="rf", trControl=trainControl(method="cv", number=10))
modFit <- train(classe ~ ., data=train, method="rf", trControl=trainControl(method="cv", number=10))
install.packages("ISLR")
library("ISLR", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?islr
?ISLR
data(ISLR)
ISLR
mean(80,125,140,85)
x <- c(80,125,140,85)
x
mean(x)
mean(c(80,125,140,85))
x <- c(1,2,3,4,5)
sd(x)
answers = rep("A", 20)
}
answers <- c("B","A","B","A", "A", "E", "D", "B", "A", "A", "B","C", "B", "A","E","E","A", "B", "B", "B")
answers
len(answers)
length(answers)
pml_write_files(answers)
pml_write_files(answers)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
answers
x <- pml_write_files(answers)
x
answer <- rep("A",20)
answer
answers
wd()
getwd()
setwd("/Users/williammcdonald/Coursera_RepData_PeerAssessment1/Answers")
data(vowel.train)
data(vowel.test)
set.seed(33833)
?train
names(vowel.train)
str(vowel.train)
vowel.train[y]<- as.factor(vowel.train[y])
vowel.train[y]
vowel.train[,y]<-as.factor(vowel.train[,y])
vowel.train
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
str(vowel.train)
str(vowel.test)
train(y~., method= "rf")
train(y~., data = vowel.train, method= "rf")
gbm <- train(y~., data = vowel.train, method = "gbm")
gbm
rf <- train(y~., data = vowel.train, method= "rf")
rf
gbm <- train(y~., data = vowel.test, method = "gbm")
gbm
?predict
predict(rf$finalModel, data = vowel.test)
x<-predict(rf$finalModel, data = vowel.test)
x
rf
rf$finalModel
gbm$finalModel
gbm <- train(y~., data = vowel.train, method = "gbm")
rfout <- predict(rf, newdata = vowel.test)
gbmout <- predict(gbm, newdata = vowel.test)
confusionMatrix(rfout, vowel.test$y)
confusionMatrix(gbmout, vowel.test$y)
predDF<- data.frame(rfout,gbmout,wage=vowel.test$y)
predDF
combModFit <- train(vowel.test$y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
sum(round(pred1)==vowel.test$y)/length(vowel.test$y)
sum(round(rfout)==vowel.test$y)/length(vowel.test$y)
combModFit$finalModel
combModFit <- train(vowel.test$y ~.,method="rf",data=predDF)
combModFit$finalModel
combModFit
predrf
predDF
head(predDF)
confusionMatrix(predDF$wage, predDF$rfout)
confusionMatrix(predDF$wage, predDF$gbmout)
confusionMatrix(predDF$rfout, predDF$gbmout)
confusionMatrix(rfout, gbmout)
confusionMatrix(rfout, vowel.test$y)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[ -inTrain,]
set.seed(62433)
rf <- train(diagnosis ~ ., data = training, method = rf)
str(training)
rf <- train(diagnosis ~ ., data = training, method = "rf")
rf
gbm <- train(diagnosis ~ ., data = training, method = "gbm")
rf$finalModel
gbm$finalModel
lda <- train(diagnosis ~ ., data = training, method = "lda")
lda
rf
gbm
p1 <- predict(rf, newdata = testing)
p2 <- predict(gbm, newdata = testing)
p3 <- predict(lda, newdata = testing)
confusionMatrix(p1, testing$diagnosis)
confusionMatrix(p2, testing$diagnosis)
confusionMatrix(p3, testing$diagnosis)
predDF <- data.frame(p1, p2, p3, diagnosis = testing$diagnosis)
comFit <- train(diagnosis ~ ., method = "rf", data = predDF)
comPred <- predict(comFit, predDF)
comAcc <- confusionMatrix(comPred, predDF$diagnosis)
comAcc
set.seed(62433)
rf <- train(diagnosis ~. , data = training, method = "rf")
set.seed(62433)
gbm <- train(diagnosis ~. , data = training, method = "gbm")
gbm
set.seed(62433)
lda <- train(diagnosis ~. , data = training, method = "lda")
pred1 <- predict(rf, newdata = testing)
pred2 <- predict(gbm, newdata = testing)
pred3 <- predict(lda, newdata = testing)
cm1 <- confusionMatrix(pred1, testing$diagnosis)
cm2 <- confusionMatrix(pred2, testing$diagnosis)
cm3 <- confusionMatrix(pred3, testing$diagnosis)
cm1
cm2
cm3
predDF <- data.frame(pred1, pred2, pred3, diagnosis = testing$diagnosis)
combiFit <- train(diagnosis ~. , data = predDF, method = "rf")
combiPred <- predict(combiFit, newdata = testing)
confusionMatrix(combiPred, testing$diagnosis)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
Ctraining = concrete[ inTrain,]
Ctesting = concrete[ -inTrain,]
set.seed(233)
View(Ctesting)
cmodel<- train(CompressiveStrength, data = Ctesting, method = "lasso")
cmodel<- train(CompressiveStrength, method = "lasso", data = Ctesting)
names(Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", data = Ctesting)
cmodel
?glmnet
?lasso
?train
names(getModeInfo())
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = .5, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = .9, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = .1, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = .99, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = 1, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = 100, data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "glmnet", data = Ctesting)
cmodel
cmodel$coef
cmodel<- train(CompressiveStrength~., method = "glmnet", lambda = 3, data = Ctesting)
cmodel$coef
cmodel
coef(cmodel, s = cmodel$lambda.1se)
?coef
cmodel<- train(CompressiveStrength~., method = "glmnet", lambda = 2, data = Ctesting)
cmodel
cmodel$coef
coef(cmodel)
cmodel<- train(CompressiveStrength~., method = "glmnet", lambda = "3", data = Ctesting)
cmodel$coef
cmodel<- train(CompressiveStrength~., method = "lasso", lambda = 2, data = Ctesting)
cmodel
cmodel<- train(CompressiveStrength~., method = "lasso",  data = Ctesting)
cmodel<- train(CompressiveStrength~., method = "ridge",  data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "ridge", lambda = 3, data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "ridge", lambda = 1, data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "ridge", lambda = 1000, data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "ridge", lambda = .1, data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "glmnet", lambda = .1, data = Ctesting)
cmodel$finalModel
cmodel<- train(CompressiveStrength~., method = "ridge", data = Ctesting)
cmodel$finalModel
cmodel$param$lambda
param$lambda
cmodel<- train(CompressiveStrength~., method = "relaxo", lambda = .1, data = Ctesting)
cmodel$finalModel
?plot.enet
plot.enet(cmodel)
plot(cmode)
plot(cmodel)
plot(cmodel$finalModel)
library(lubridate)
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("forecast")
?bats
?bats()
library("forecast", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
?bats()
bats(training)
names(training)
head(training)
bats(training$date)
c <- bats(training$date)
c$finalModel
c
set.seed(3523)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
svm(CompressiveStrength~.,data = training)
svmModel <- svm(CompressiveStrength~.,data = training)
svmPred <- predict(svmModel, newdata = testing)
svmPred$finalModel
svmPred
svmModel
svmPred$RMSE
RMSE(svmPred)
?RMSE
sum(svmPred)
RMSE(svmPred, na.rm = T)
mean(svmPred)
sd(svmPred)
